{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "This notebook is an example of a PRE-PROCESSING pipeline for satellite images with LAI data.\n",
    "It is not meant to be run as a script, but rather to be used as a reference for how to use the preprocessing functions.\n",
    "\n",
    "**IMPORTANT** This notebook assumes one has stored a series of *unpacked* RAS and RHD files in the VISTA format containing \n",
    "- The Leaf Area Index (LAI) values as a tensor of images over time.\n",
    "- Information of the datetimes and the coordinates of the images. \n",
    "\n",
    "The VISTA format is not publicly available, but the functions in this notebook can be used as a reference for how to preprocess satellite images in general.\n",
    "\n",
    "*Example scenario*: We have downloaded the RAS and RHD files containing the LAI values for a sentinel-2 tile (~12k by 12k image) over the span of 2020. We want to preprocess this data into timeseries for further analysis.\n",
    "\n",
    "*Author*: Jens d'Hondt (TU Eindhoven)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import sys\n",
    "import seaborn as sns\n",
    "from eolearn.core import EOPatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Unpacking the data\n",
    "\n",
    "This step unapacks a RAS-RHD file pair with LAI values into a series of .npy files, named by the date of the image.\n",
    "(e.g. `2020_1_1.npy`, `2020_1_2.npy`, ...) \n",
    "The unpacking can be done using the `unpack_vista_unzipped` function in `stelar_spatiotemporal/preprocessing/vista_preprocessing.py`, as shown below.\n",
    "\n",
    "**Assumptions**:\n",
    "- One has downloaded and unzipped the RAS and RHD files to be processed.\n",
    "- The RAS files can contain multiple images, each with a different date, month or year.\n",
    "\n",
    "**Process**:\n",
    "The function `unpack_vista_unzipped` will do the following:\n",
    "1. Extract the images from the RAS file and store them in a series of .npy files named by the date of the individual image, based on the accompanied RHD file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set minio credentials\n",
    "os.environ[\"MINIO_ENDPOINT_URL\"] = \"http://localhost:9000\"\n",
    "os.environ[\"MINIO_ACCESS_KEY\"] = \"minioadmin\"\n",
    "os.environ[\"MINIO_SECRET_KEY\"] = \"minioadmin\"\n",
    "\n",
    "S3DATADIR = \"s3://stelar-spatiotemporal/LAI\"\n",
    "LOCAL_DATADIR = \"/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacking 87 images from s3://stelar-spatiotemporal/LAI/30TYQ_LAI_2020.RAS\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jens/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/src/STELAR_spatiotemporal/image2ts_pipeline.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jens/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/src/STELAR_spatiotemporal/image2ts_pipeline.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m outdir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(LOCAL_DATADIR, \u001b[39m\"\u001b[39m\u001b[39mnpys\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jens/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/src/STELAR_spatiotemporal/image2ts_pipeline.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Unpacks RAS and RHD files into numpy arrays\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jens/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/src/STELAR_spatiotemporal/image2ts_pipeline.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m unpack_vista_unzipped(ras_path, rhd_path, outdir, crs\u001b[39m=\u001b[39;49mCRS(\u001b[39m32630\u001b[39;49m))\n",
      "File \u001b[0;32m~/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/src/STELAR_spatiotemporal/stelar_spatiotemporal/preprocessing/vista_preprocessing.py:96\u001b[0m, in \u001b[0;36munpack_vista_unzipped\u001b[0;34m(ras_path, rhd_path, outdir, delete_after, crs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39m# Unpack all images from ras file and save as .npy files\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnpacking \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(timestamps)\u001b[39m}\u001b[39;00m\u001b[39m images from \u001b[39m\u001b[39m{\u001b[39;00mras_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 96\u001b[0m unpack_ras(ras_path, outdir, timestamps, img_w, img_h)\n\u001b[1;32m     98\u001b[0m \u001b[39m# Delete RAS and RHD files\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m delete_after:\n",
      "File \u001b[0;32m~/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/src/STELAR_spatiotemporal/stelar_spatiotemporal/preprocessing/vista_preprocessing.py:23\u001b[0m, in \u001b[0;36munpack_ras\u001b[0;34m(ras_path, outdir, timestamps, img_w, img_h)\u001b[0m\n\u001b[1;32m     21\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(timestamps)\n\u001b[1;32m     22\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[0;32m---> 23\u001b[0m     chunk \u001b[39m=\u001b[39m ras_file\u001b[39m.\u001b[39;49mread(img_len\u001b[39m*\u001b[39;49mdata_size)\n\u001b[1;32m     24\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunk:\n\u001b[1;32m     25\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not read image \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mn\u001b[39m}\u001b[39;00m\u001b[39m, might be out of bounds\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/.venv/lib/python3.10/site-packages/fsspec/spec.py:1858\u001b[0m, in \u001b[0;36mAbstractBufferedFile.read\u001b[0;34m(self, length)\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[39mif\u001b[39;00m length \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1856\u001b[0m     \u001b[39m# don't even bother calling fetch\u001b[39;00m\n\u001b[1;32m   1857\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1858\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache\u001b[39m.\u001b[39;49m_fetch(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloc, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloc \u001b[39m+\u001b[39;49m length)\n\u001b[1;32m   1859\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(out)\n\u001b[1;32m   1860\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/.venv/lib/python3.10/site-packages/fsspec/caching.py:156\u001b[0m, in \u001b[0;36mReadAheadCache._fetch\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m    154\u001b[0m     part \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m end \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize, end \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocksize)\n\u001b[0;32m--> 156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfetcher(start, end)  \u001b[39m# new block replaces old\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart \u001b[39m=\u001b[39m start\n\u001b[1;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache)\n",
      "File \u001b[0;32m~/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/.venv/lib/python3.10/site-packages/s3fs/core.py:2220\u001b[0m, in \u001b[0;36mS3File._fetch_range\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m   2218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fetch_range\u001b[39m(\u001b[39mself\u001b[39m, start, end):\n\u001b[1;32m   2219\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2220\u001b[0m         \u001b[39mreturn\u001b[39;00m _fetch_range(\n\u001b[1;32m   2221\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfs,\n\u001b[1;32m   2222\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbucket,\n\u001b[1;32m   2223\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey,\n\u001b[1;32m   2224\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mversion_id,\n\u001b[1;32m   2225\u001b[0m             start,\n\u001b[1;32m   2226\u001b[0m             end,\n\u001b[1;32m   2227\u001b[0m             req_kw\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreq_kw,\n\u001b[1;32m   2228\u001b[0m         )\n\u001b[1;32m   2230\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m   2231\u001b[0m         \u001b[39mif\u001b[39;00m ex\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m errno\u001b[39m.\u001b[39mEINVAL \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mpre-conditions\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m ex\u001b[39m.\u001b[39margs[\u001b[39m1\u001b[39m]:\n",
      "File \u001b[0;32m~/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/.venv/lib/python3.10/site-packages/s3fs/core.py:2382\u001b[0m, in \u001b[0;36m_fetch_range\u001b[0;34m(fs, bucket, key, version_id, start, end, req_kw)\u001b[0m\n\u001b[1;32m   2380\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2381\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mFetch: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, bucket, key, start, end)\n\u001b[0;32m-> 2382\u001b[0m \u001b[39mreturn\u001b[39;00m sync(fs\u001b[39m.\u001b[39;49mloop, _inner_fetch, fs, bucket, key, version_id, start, end, req_kw)\n",
      "File \u001b[0;32m~/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/.venv/lib/python3.10/site-packages/fsspec/asyn.py:91\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m asyncio\u001b[39m.\u001b[39mrun_coroutine_threadsafe(_runner(event, coro, result, timeout), loop)\n\u001b[1;32m     89\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     \u001b[39m# this loops allows thread to get interrupted\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     \u001b[39mif\u001b[39;00m event\u001b[39m.\u001b[39;49mwait(\u001b[39m1\u001b[39;49m):\n\u001b[1;32m     92\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    608\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    325\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sentinelhub import CRS\n",
    "from stelar_spatiotemporal.preprocessing.vista_preprocessing import unpack_vista_unzipped\n",
    "\n",
    "ras_path = os.path.join(S3DATADIR, \"30TYQ_LAI_2020.RAS\")\n",
    "rhd_path = os.path.join(S3DATADIR, \"30TYQ_LAI_2020.RHD\")\n",
    "\n",
    "outdir = os.path.join(LOCAL_DATADIR, \"npys\")\n",
    "\n",
    "# Unpacks RAS and RHD files into numpy arrays\n",
    "unpack_vista_unzipped(ras_path, rhd_path, outdir, crs=CRS(32630))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option A: Batch processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Combining images to eopatches\n",
    "\n",
    "In this step we will combine the individual LAI images into a tensor, or package of images. \n",
    "\n",
    "**Assumptions**:\n",
    "- One has stored the .npy files containing the images in a folder `$DATADIR` following the structure `DATADIR/npys/{date}.npy`.\n",
    "\n",
    "**Process**:\n",
    "The function `combine_bands` will do the following:\n",
    "1. Partition the .npy files into a series of EOPatches, each containing a tensor of images, the corresponding datetimes and bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5 partitions of 19 dates each\n",
      "Saving eopatch 5/5on 5/5\r"
     ]
    }
   ],
   "source": [
    "from stelar_spatiotemporal.preprocessing.preprocessing import combine_npys_into_eopatches, max_partition_size\n",
    "from stelar_spatiotemporal.lib import load_bbox\n",
    "\n",
    "npy_dir = os.path.join(LOCAL_DATADIR, \"npys\")\n",
    "\n",
    "npy_paths = glob.glob(os.path.join(npy_dir,\"*.npy\"))\n",
    "max_partition_size = max_partition_size(npy_paths[0], MAX_RAM=int(4 * 1e9))\n",
    "\n",
    "bbox = load_bbox(os.path.join(npy_dir, \"bbox.pkl\"))\n",
    "\n",
    "outpath = os.path.join(LOCAL_DATADIR, \"lai_eopatch\")\n",
    "combine_npys_into_eopatches(npy_paths=npy_paths, \n",
    "                            outpath=outpath,\n",
    "                            feature_name=\"LAI\",\n",
    "                            bbox=bbox,\n",
    "                            partition_size=max_partition_size,\n",
    "                            delete_after=True,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 LAI to CSV\n",
    "\n",
    "In this step we will convert the LAI values to a timeseries of LAI values for each pixel OR field (extracted in the segmentation pipeline).\n",
    "The conversion into timeseries will be done per image.\n",
    "\n",
    "The values for collections of pixels and/or fields will be stored as column-major csv file with pixel/field ids as columns, and dates as rows. This is to facilitate appending of new data.\n",
    "The values for pixels will be partitioned by *patchlets*, which are subsets of the full image. This is done to reduce the size of the csv files.\n",
    "\n",
    "**Assumptions**:\n",
    "- One has stored the EOPatch objects in a folder `$DATADIR` (see step 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 LAI to CSV: pixel values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Approach 1: npys -> eopatches -> p patchlets per date -> p patchlets -> timeseries\n",
    "\n",
    "**Process**:\n",
    "The function `lai_to_csv_px` will do the following:\n",
    "\n",
    "1. We break up each image into a series of patchlets.\n",
    "2. We combine the data for each patchlet into a single eopatch.\n",
    "3. We convert the eopatch into a timeseries of LAI values for each pixel.\n",
    "4. (Optional) Combine the timeseries of LAI values for each pixel into a single csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1. Splitting tiles into patchlets: 100%|██████████| 5/5 [04:17<00:00, 51.43s/it]\n",
      "2. Combining dates per patchlet: 100%|██████████| 81/81 [00:53<00:00,  1.50it/s]\n",
      "3. Extracting timeseries per patchlet:   5%|▍         | 4/81 [02:18<44:18, 34.52s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jens/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/src/STELAR_spatiotemporal/image2ts_pipeline.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jens/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/src/STELAR_spatiotemporal/image2ts_pipeline.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m outdir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(S3DATADIR, \u001b[39m\"\u001b[39m\u001b[39mlai_px_timeseries\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jens/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/src/STELAR_spatiotemporal/image2ts_pipeline.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Turn the LAI values into a csv file\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jens/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/src/STELAR_spatiotemporal/image2ts_pipeline.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m lai_to_csv_px(eop_paths, patchlet_dir\u001b[39m=\u001b[39;49mpatchlet_dir, outdir\u001b[39m=\u001b[39;49moutdir, delete_patchlets\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/src/STELAR_spatiotemporal/stelar_spatiotemporal/preprocessing/timeseries.py:132\u001b[0m, in \u001b[0;36mlai_to_csv_px\u001b[0;34m(eop_paths, patchlet_dir, outdir, n_jobs, delete_patchlets)\u001b[0m\n\u001b[1;32m    130\u001b[0m patchlet_paths\u001b[39m.\u001b[39msort()\n\u001b[1;32m    131\u001b[0m \u001b[39mfor\u001b[39;00m ppath \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(patchlet_paths, total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(patchlet_paths), desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m3. Extracting timeseries per patchlet\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 132\u001b[0m     extract_px_timeseries_wrapper(eop_path\u001b[39m=\u001b[39;49mppath, outdir \u001b[39m=\u001b[39;49m outdir)\n\u001b[1;32m    134\u001b[0m \u001b[39m# 4. Deleting the patchlets\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39mif\u001b[39;00m delete_patchlets:\n",
      "File \u001b[0;32m~/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/src/STELAR_spatiotemporal/stelar_spatiotemporal/preprocessing/timeseries.py:44\u001b[0m, in \u001b[0;36mextract_px_timeseries_wrapper\u001b[0;34m(eop_path, outdir, band)\u001b[0m\n\u001b[1;32m     42\u001b[0m os\u001b[39m.\u001b[39mmakedirs(outdir, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     43\u001b[0m outpath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(outdir, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(eop_path) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m \u001b[39mreturn\u001b[39;00m extract_px_timeseries(eopatch, outpath\u001b[39m=\u001b[39;49moutpath, band\u001b[39m=\u001b[39;49mband)\n",
      "File \u001b[0;32m~/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/src/STELAR_spatiotemporal/stelar_spatiotemporal/preprocessing/timeseries.py:69\u001b[0m, in \u001b[0;36mextract_px_timeseries\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     66\u001b[0m xs, ys \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmeshgrid(np\u001b[39m.\u001b[39marange(arr\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]), np\u001b[39m.\u001b[39marange(arr\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]))\n\u001b[1;32m     68\u001b[0m \u001b[39m# Turn xs into \"x0 x1 x2 ... xn\" and ys into \"y0 y1 y2 ... yn\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m xs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mchar\u001b[39m.\u001b[39madd(xs\u001b[39m.\u001b[39;49mravel()\u001b[39m.\u001b[39;49mastype(\u001b[39mstr\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     70\u001b[0m ys \u001b[39m=\u001b[39m ys\u001b[39m.\u001b[39mravel()\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\n\u001b[1;32m     71\u001b[0m cols \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mchar\u001b[39m.\u001b[39madd(xs, ys)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from stelar_spatiotemporal.preprocessing.timeseries import lai_to_csv_px\n",
    "\n",
    "eop_dir = os.path.join(LOCAL_DATADIR, \"lai_eopatch\")\n",
    "eop_paths = glob.glob(os.path.join(eop_dir, \"partition_*\"))\n",
    "if len(eop_paths) == 0: eop_paths = [eop_dir]\n",
    "\n",
    "patchlet_dir = os.path.join(LOCAL_DATADIR, \"patchlets\")\n",
    "\n",
    "outdir = os.path.join(S3DATADIR, \"lai_px_timeseries\")\n",
    "\n",
    "# Turn the LAI values into a csv file\n",
    "lai_to_csv_px(eop_paths, patchlet_dir=patchlet_dir, outdir=outdir, delete_patchlets=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_0</th>\n",
       "      <th>1_0</th>\n",
       "      <th>2_0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-11</th>\n",
       "      <td>3.049</td>\n",
       "      <td>3.430</td>\n",
       "      <td>4.242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-14</th>\n",
       "      <td>2.666</td>\n",
       "      <td>3.196</td>\n",
       "      <td>4.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-16</th>\n",
       "      <td>3.192</td>\n",
       "      <td>3.408</td>\n",
       "      <td>4.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-19</th>\n",
       "      <td>4.084</td>\n",
       "      <td>4.355</td>\n",
       "      <td>4.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-03</th>\n",
       "      <td>1.891</td>\n",
       "      <td>2.129</td>\n",
       "      <td>3.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-05</th>\n",
       "      <td>2.997</td>\n",
       "      <td>2.776</td>\n",
       "      <td>3.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-15</th>\n",
       "      <td>1.063</td>\n",
       "      <td>1.309</td>\n",
       "      <td>1.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-20</th>\n",
       "      <td>3.056</td>\n",
       "      <td>3.742</td>\n",
       "      <td>4.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-09</th>\n",
       "      <td>2.494</td>\n",
       "      <td>2.738</td>\n",
       "      <td>2.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-21</th>\n",
       "      <td>2.633</td>\n",
       "      <td>2.924</td>\n",
       "      <td>3.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-24</th>\n",
       "      <td>2.735</td>\n",
       "      <td>3.300</td>\n",
       "      <td>3.602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>2.320</td>\n",
       "      <td>3.070</td>\n",
       "      <td>4.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-03</th>\n",
       "      <td>2.830</td>\n",
       "      <td>3.249</td>\n",
       "      <td>3.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-05</th>\n",
       "      <td>2.971</td>\n",
       "      <td>4.308</td>\n",
       "      <td>4.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-08</th>\n",
       "      <td>3.310</td>\n",
       "      <td>4.339</td>\n",
       "      <td>4.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-10</th>\n",
       "      <td>1.662</td>\n",
       "      <td>3.794</td>\n",
       "      <td>3.833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0_0    1_0    2_0\n",
       "index                          \n",
       "2020-01-06    NaN    NaN    NaN\n",
       "2020-01-11  3.049  3.430  4.242\n",
       "2020-01-14  2.666  3.196  4.372\n",
       "2020-01-16  3.192  3.408  4.193\n",
       "2020-01-19  4.084  4.355  4.898\n",
       "2020-02-03  1.891  2.129  3.051\n",
       "2020-02-05  2.997  2.776  3.700\n",
       "2020-02-15  1.063  1.309  1.589\n",
       "2020-02-18    NaN    NaN    NaN\n",
       "2020-02-20  3.056  3.742  4.297\n",
       "2020-03-09  2.494  2.738  2.809\n",
       "2020-03-19    NaN    NaN    NaN\n",
       "2020-03-21  2.633  2.924  3.762\n",
       "2020-03-24  2.735  3.300  3.602\n",
       "2020-03-26    NaN    NaN    NaN\n",
       "2020-03-31  2.320  3.070  4.020\n",
       "2020-04-03  2.830  3.249  3.518\n",
       "2020-04-05  2.971  4.308  4.591\n",
       "2020-04-08  3.310  4.339  4.080\n",
       "2020-04-10  1.662  3.794  3.833"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file\n",
    "path = \"/home/jens/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/VISTA/VISTA_workbench/data/pipeline_example/lai_px_timeseries/patchlet_4_4.csv\"\n",
    "\n",
    "df = pd.read_csv(path, index_col=0, parse_dates=True, usecols=np.arange(0, 4))\n",
    "df[df < 0] = np.nan\n",
    "df /= 1000\n",
    "df.sort_index(inplace=True)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 LAI to CSV: field values\n",
    "\n",
    "**Process**:\n",
    "The function `lai_to_csv_field` will do the following:\n",
    "\n",
    "1. Temporarily save the (partitioned) eopatches as tiffs (necessary for masking with field shapes)\n",
    "2. For each tiff:\n",
    "    1. Load the LAI values.\n",
    "    2. For each field:\n",
    "        1. Mask the LAI values for the field.\n",
    "        2. Take the median of the LAI values for the field for each date.\n",
    "        3. Append the LAI values for the field to the corresponding csv file.\n",
    "3. (Optional) Combine the timeseries of LAI values for each pixel into a single csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing eopatch 1/5\n",
      "1. Temporarily saving eopatch as tiff\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jens/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/src/STELAR_spatiotemporal/image2ts_pipeline.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jens/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/src/STELAR_spatiotemporal/image2ts_pipeline.ipynb#X43sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m fields_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39ms3://stelar-spatiotemporal/fields.gpkg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jens/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/src/STELAR_spatiotemporal/image2ts_pipeline.ipynb#X43sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Perform the process as described above\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jens/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/src/STELAR_spatiotemporal/image2ts_pipeline.ipynb#X43sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m lai_to_csv_field(eop_paths, fields_path\u001b[39m=\u001b[39;49mfields_path, outdir\u001b[39m=\u001b[39;49mS3DATADIR, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m, delete_tmp\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/src/STELAR_spatiotemporal/stelar_spatiotemporal/preprocessing/timeseries.py:356\u001b[0m, in \u001b[0;36mlai_to_csv_field\u001b[0;34m(eop_paths, fields_path, outdir, nfields, n_jobs, delete_tmp, tmpdir)\u001b[0m\n\u001b[1;32m    354\u001b[0m tiff_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(tif_dir, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(eop_path) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.tiff\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    355\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(tiff_path):\n\u001b[0;32m--> 356\u001b[0m         export_eopatch_to_tiff(eop_path, tiff_path, feature\u001b[39m=\u001b[39;49m(FeatureType\u001b[39m.\u001b[39;49mDATA, \u001b[39m\"\u001b[39;49m\u001b[39mLAI\u001b[39;49m\u001b[39m\"\u001b[39;49m), nodata\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, channel_pos\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m    358\u001b[0m \u001b[39m# 3. For each field, mask the tiff, get median and save timeseries as csv\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m3. Masking tiff and saving timeseries\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/ownCloud/Documents/3.Werk/0.TUe_Research/0.STELAR/0.VISTA/VISTA_workbench/src/STELAR_spatiotemporal/stelar_spatiotemporal/lib.py:165\u001b[0m, in \u001b[0;36mexport_eopatch_to_tiff\u001b[0;34m(eop_path, out_path, feature, nodata, channel_pos)\u001b[0m\n\u001b[1;32m    157\u001b[0m dst_transform \u001b[39m=\u001b[39m rasterio\u001b[39m.\u001b[39mtransform\u001b[39m.\u001b[39mfrom_bounds(\u001b[39m*\u001b[39meopatch\u001b[39m.\u001b[39mbbox, width\u001b[39m=\u001b[39mwidth, height\u001b[39m=\u001b[39mheight)\n\u001b[1;32m    159\u001b[0m \u001b[39mwith\u001b[39;00m rasterio\u001b[39m.\u001b[39mopen(out_path, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, driver\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mGTiff\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    160\u001b[0m                     width\u001b[39m=\u001b[39mwidth, height\u001b[39m=\u001b[39mheight,\n\u001b[1;32m    161\u001b[0m                     count\u001b[39m=\u001b[39mchannel_count,\n\u001b[1;32m    162\u001b[0m                     dtype\u001b[39m=\u001b[39mimage_array\u001b[39m.\u001b[39mdtype, nodata\u001b[39m=\u001b[39mnodata,\n\u001b[1;32m    163\u001b[0m                     transform\u001b[39m=\u001b[39mdst_transform, crs\u001b[39m=\u001b[39mdst_crs,\n\u001b[1;32m    164\u001b[0m                     compress\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDEFLATE\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m dst:\n\u001b[0;32m--> 165\u001b[0m     dst\u001b[39m.\u001b[39;49mwrite(image_array)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from stelar_spatiotemporal.preprocessing.timeseries import lai_to_csv_field\n",
    "\n",
    "eop_dir = os.path.join(LOCAL_DATADIR, \"lai_eopatch\")\n",
    "eop_paths = glob.glob(os.path.join(eop_dir, \"partition_*\"))\n",
    "if len(eop_paths) == 0: eop_paths = [eop_dir]\n",
    "\n",
    "eop_paths.sort()\n",
    "fields_path = \"s3://stelar-spatiotemporal/fields.gpkg\"\n",
    "\n",
    "# Perform the process as described above\n",
    "lai_to_csv_field(eop_paths, fields_path=fields_path, outdir=S3DATADIR, n_jobs=16, delete_tmp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-24</th>\n",
       "      <td>2104.0</td>\n",
       "      <td>542.0</td>\n",
       "      <td>387.5</td>\n",
       "      <td>271.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>3268.0</td>\n",
       "      <td>2348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>807.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2910.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4304.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>763.5</td>\n",
       "      <td>554.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-11</th>\n",
       "      <td>1754.0</td>\n",
       "      <td>1579.0</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>869.0</td>\n",
       "      <td>267.5</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>3920.0</td>\n",
       "      <td>2500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-14</th>\n",
       "      <td>2036.0</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>786.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1794.0</td>\n",
       "      <td>775.0</td>\n",
       "      <td>2728.0</td>\n",
       "      <td>1779.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0       3       4      5      6       7      8       9  \\\n",
       "2020-03-24  2104.0   542.0   387.5  271.0  171.0  3576.0  637.0  3268.0   \n",
       "2020-01-06     NaN     NaN     NaN  807.0    NaN  2910.0    NaN  4304.0   \n",
       "2020-03-19     NaN     NaN   763.5  554.0    NaN     NaN    NaN  2084.0   \n",
       "2020-01-11  1754.0  1579.0  1117.0  869.0  267.5  2756.0  784.0  3920.0   \n",
       "2020-01-14  2036.0  1118.0   922.0  786.0  204.0  1794.0  775.0  2728.0   \n",
       "\n",
       "                10  \n",
       "2020-03-24  2348.0  \n",
       "2020-01-06     NaN  \n",
       "2020-03-19     NaN  \n",
       "2020-01-11  2500.0  \n",
       "2020-01-14  1779.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read csv file\n",
    "csv_path = os.path.join(DATADIR, \"lai_field_timeseries.csv\")\n",
    "df_field = pd.read_csv(csv_path, index_col=0, usecols=np.arange(10))\n",
    "\n",
    "df_field.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
